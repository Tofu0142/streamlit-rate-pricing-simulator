{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rate_pricing.model_config import ModelConfigs\n",
    "from rate_pricing.training import Trainer, TrainingData, ModelMetrics, TrainingChannel\n",
    "from rate_pricing.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = ModelConfigs(collect=True, include_inactive=True)\n",
    "model_config = model_configs[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"s3://pps-preprod-data-lake-data-science/tables/mab_training_dataset/requested_on=2024-04-03/\"\n",
    "test_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    input_data,\n",
    "    engine='pyarrow',  # or use 'fastparquet'\n",
    "    storage_options={\"profile\": 'Prep_DS'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>requested_at</th>\n",
       "      <th>affiliate_group_id</th>\n",
       "      <th>sell_rate_usd</th>\n",
       "      <th>sell_currency</th>\n",
       "      <th>profit_estimate_usd</th>\n",
       "      <th>total_nightly_rate</th>\n",
       "      <th>default_supplier_adjustment</th>\n",
       "      <th>default_supplier_percent_adjustment</th>\n",
       "      <th>global_adjustment</th>\n",
       "      <th>global_percent_adjustment</th>\n",
       "      <th>property_adjustment</th>\n",
       "      <th>tax</th>\n",
       "      <th>tax_recovery_fee</th>\n",
       "      <th>tax_recovery_fee_offset</th>\n",
       "      <th>fees_collected_at_booking</th>\n",
       "      <th>total</th>\n",
       "      <th>converted</th>\n",
       "      <th>recorded_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063bfd9f58fc15bc6f5155d</td>\n",
       "      <td>2024-04-03 07:56:46</td>\n",
       "      <td>525ebb7f701c6366050000e7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>AUD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1230.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.759998</td>\n",
       "      <td>27.58</td>\n",
       "      <td>272.119995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.129997</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1711.27</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-04 07:22:20.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107d1872869aef7cc827b740</td>\n",
       "      <td>2024-04-03 07:49:52</td>\n",
       "      <td>5ed59db3881860372aeb319b</td>\n",
       "      <td>0.000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.000</td>\n",
       "      <td>770.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.160004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1045.19</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-04 07:22:20.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10a14822a1caea82eaf944d6</td>\n",
       "      <td>2024-04-03 07:59:26</td>\n",
       "      <td>62e83fa60a31a612b967ae0d</td>\n",
       "      <td>0.000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1586.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.099998</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.710007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.11</td>\n",
       "      <td>1931.08</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-04 07:22:20.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10daa8849925f12a0c036b42</td>\n",
       "      <td>2024-04-03 07:20:38</td>\n",
       "      <td>636aa622b84f5e00538a4f88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10291.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-252.139999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1916.109985</td>\n",
       "      <td>399.420013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12354.86</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-04 07:22:20.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10fef0f26fff6234335ba228</td>\n",
       "      <td>2024-04-03 07:38:38</td>\n",
       "      <td>5ed59e14881860372aeb777c</td>\n",
       "      <td>0.000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.000</td>\n",
       "      <td>518.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.029999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.790001</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>633.46</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-04-04 07:22:20.462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_id        requested_at        affiliate_group_id  \\\n",
       "0  1063bfd9f58fc15bc6f5155d 2024-04-03 07:56:46  525ebb7f701c6366050000e7   \n",
       "1  107d1872869aef7cc827b740 2024-04-03 07:49:52  5ed59db3881860372aeb319b   \n",
       "2  10a14822a1caea82eaf944d6 2024-04-03 07:59:26  62e83fa60a31a612b967ae0d   \n",
       "3  10daa8849925f12a0c036b42 2024-04-03 07:20:38  636aa622b84f5e00538a4f88   \n",
       "4  10fef0f26fff6234335ba228 2024-04-03 07:38:38  5ed59e14881860372aeb777c   \n",
       "\n",
       "  sell_rate_usd sell_currency profit_estimate_usd total_nightly_rate  \\\n",
       "0         0.000           AUD               0.000            1230.15   \n",
       "1         0.000           EUR               0.000             770.78   \n",
       "2         0.000           USD               0.000            1586.16   \n",
       "3         0.000           USD               0.000           10291.47   \n",
       "4         0.000           EUR               0.000             518.35   \n",
       "\n",
       "   default_supplier_adjustment  default_supplier_percent_adjustment  \\\n",
       "0                          0.0                            33.759998   \n",
       "1                          0.0                            55.500000   \n",
       "2                          0.0                           106.099998   \n",
       "3                          0.0                             0.000000   \n",
       "4                          0.0                            67.029999   \n",
       "\n",
       "   global_adjustment  global_percent_adjustment  property_adjustment  \\\n",
       "0              27.58                 272.119995                  0.0   \n",
       "1               0.00                  64.750000                  0.0   \n",
       "2               0.00                   0.000000                  0.0   \n",
       "3               0.00                -252.139999                  0.0   \n",
       "4               0.00                  -9.500000                  0.0   \n",
       "\n",
       "           tax  tax_recovery_fee  tax_recovery_fee_offset  \\\n",
       "0   125.129997         22.530001                      0.0   \n",
       "1   154.160004          0.000000                      0.0   \n",
       "2   149.710007          0.000000                      0.0   \n",
       "3  1916.109985        399.420013                      0.0   \n",
       "4    53.790001          3.790000                      0.0   \n",
       "\n",
       "  fees_collected_at_booking     total  converted             recorded_at  \n",
       "0                      0.00   1711.27      False 2024-04-04 07:22:20.462  \n",
       "1                      0.00   1045.19      False 2024-04-04 07:22:20.462  \n",
       "2                     89.11   1931.08      False 2024-04-04 07:22:20.462  \n",
       "3                      0.00  12354.86      False 2024-04-04 07:22:20.462  \n",
       "4                      0.00    633.46      False 2024-04-04 07:22:20.462  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = (\n",
    "    model_config.data.s3_url.format(bucket=settings.training_data_bucket)\n",
    "    if input_data is None\n",
    "    else input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = TrainingData(\n",
    "    train_path=training_data_path,\n",
    "    data_config=model_config.data,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = training_data.read(TrainingChannel.TRAIN, profile=\"Prep_DS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "import os \n",
    "\n",
    "DATA_DIRECTORY = \"d3rlpy_data\"\n",
    "DROPBOX_URL = \"https://www.dropbox.com/s\"\n",
    "CARTPOLE_URL = f\"{DROPBOX_URL}/uep0lzlhxpi79pd/cartpole_v1.1.0.h5?dl=1\"\n",
    "url = CARTPOLE_URL\n",
    "file_name = \"cartpole_replay_v1.1.0.h5\"\n",
    "data_path = os.path.join(DATA_DIRECTORY, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xizhang/.pyenv/versions/streamlit-my-app/envs/3.11.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-18 11:51:41,240\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-04-18 11:51:42,433\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-04-18 11:51:42,889\tWARNING compression.py:16 -- lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from ray.rllib.policy.sample_batch import convert_ma_batch_to_sample_batch\n",
    "from ray.rllib.algorithms import cql as cql \n",
    "from ray.rllib.algorithms import DQN    \n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.offline.estimators import (\n",
    "    ImportanceSampling,\n",
    "    WeightedImportanceSampling,\n",
    "    DirectMethod,\n",
    "    DoublyRobust,\n",
    ")\n",
    "from ray.rllib.offline.estimators.fqe_torch_model import FQETorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--stop-reward'], dest='stop_reward', nargs=None, const=None, default=50.0, type=<class 'float'>, choices=None, required=False, help='Reward at which we stop training.', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--as-test\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether this script should be run as a test: --stop-reward must \"\n",
    "    \"be achieved within --stop-timesteps AND --stop-iters.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stop-iters\", type=int, default=5, help=\"Number of iterations to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--stop-reward\", type=float, default=50.0, help=\"Reward at which we stop training.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 13:02:49,288\tINFO policy.py:1272 -- Policy (worker=local) running on CPU.\n",
      "2024-04-18 13:02:49,289\tINFO torch_policy.py:183 -- Found 0 visible cuda devices.\n",
      "2024-04-18 13:02:49,297\tINFO cql_torch_policy.py:89 -- Current iteration = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 13:02:49,308\tINFO util.py:118 -- Using connectors:\n",
      "2024-04-18 13:02:49,309\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-04-18 13:02:49,309\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-04-18 13:02:49,309\tINFO rollout_worker.py:1758 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2024-04-18 13:02:49,310\tINFO rollout_worker.py:1759 -- Built preprocessor map: {'default_policy': None}\n",
      "2024-04-18 13:02:49,310\tINFO rollout_worker.py:560 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2024-04-18 13:02:52,066\tINFO worker_set.py:324 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Box([-1. -1. -8.], [1. 1. 8.], (3,), float32), Box(-2.0, 2.0, (1,), float32)), '__env__': (Box([-1. -1. -8.], [1. 1. 8.], (3,), float32), Box(-2.0, 2.0, (1,), float32))}\n",
      "2024-04-18 13:02:52,077\tINFO policy.py:1272 -- Policy (worker=local) running on CPU.\n",
      "2024-04-18 13:02:52,077\tINFO torch_policy.py:183 -- Found 0 visible cuda devices.\n",
      "2024-04-18 13:02:52,083\tINFO util.py:118 -- Using connectors:\n",
      "2024-04-18 13:02:52,083\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-04-18 13:02:52,083\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-04-18 13:02:52,084\tINFO rollout_worker.py:1758 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2024-04-18 13:02:52,084\tINFO rollout_worker.py:1759 -- Built preprocessor map: {'default_policy': None}\n",
      "2024-04-18 13:02:52,084\tINFO rollout_worker.py:560 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2024-04-18 13:02:52,085\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "#args = parser.parse_args()\n",
    "\n",
    "    # See rllib/tuned_examples/cql/pendulum-cql.yaml for comparison.\n",
    "config = (\n",
    "        cql.CQLConfig()\n",
    "        .framework(framework=\"torch\")\n",
    "        .rollouts(num_rollout_workers=0)\n",
    "        .debugging(log_level=\"INFO\")\n",
    "        .environment(\"Pendulum-v1\", normalize_actions=True)\n",
    "        .offline_data(\n",
    "            input_config={\n",
    "                \"paths\": [\"tests/data/pendulum/enormous.zip\"],\n",
    "                \"format\": \"json\",\n",
    "            }\n",
    "        )\n",
    "        .evaluation(\n",
    "            evaluation_num_workers=1,\n",
    "            evaluation_interval=1,\n",
    "            evaluation_duration=10,\n",
    "            evaluation_duration_unit=\"episodes\",\n",
    "            evaluation_config={\n",
    "                \"input\": \"sampler\",\n",
    "                \"postprocess_inputs\": False,\n",
    "                \"postprocess_outputs\": False,\n",
    "            },\n",
    " \n",
    "\n",
    "        \n",
    "        \n",
    "        )\n",
    "    )\n",
    "    # evaluation_parallel_to_training should be False b/c iterations are very long\n",
    "    # and this would cause evaluation to lag one iter behind training.\n",
    "\n",
    "    # Check, whether we can learn from the given file in `num_iterations`\n",
    "    # iterations, up to a reward of `min_reward`.\n",
    "num_iterations = 5\n",
    "min_reward = -300\n",
    "\n",
    "# Test for torch framework (tf not implemented yet).\n",
    "\n",
    "cql_algorithm = cql.CQL(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnt = False\n",
    "for i in range(num_iterations):\n",
    "    print(f\"Iter {i}\")\n",
    "    eval_results = cql_algorithm.train().get(\"evaluation\")\n",
    "    if eval_results:\n",
    "        print(\"... R={}\".format(eval_results[\"episode_reward_mean\"]))\n",
    "        # Learn until some reward is reached on an actual live env.\n",
    "        if eval_results[\"episode_reward_mean\"] >= min_reward:\n",
    "            # Test passed gracefully.\n",
    "            \n",
    "            print(\"Test passed after {} iterations.\".format(i))\n",
    "            quit(0)\n",
    "            learnt = True\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.execution.rollout_ops import (\n",
    "    synchronous_parallel_sample,\n",
    ")\n",
    "\n",
    "torch, _ = try_import_torch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cql_policy = cql_algorithm.get_policy()\n",
    "cql_model = cql_policy.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:25:02,679\tINFO streaming_executor.py:112 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-04-18_11-52-57_167737_73576/logs\n",
      "2024-04-18 12:25:02,680\tINFO streaming_executor.py:113 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadJSON] -> LimitOperator[limit=1]\n",
      "\n",
      "                                                \n",
      "\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.4835519790649414, -0.8753156661987305, 0.0943986102938652],\n",
       " [0.4569772481918335, -0.8894783854484558, -0.6022850275039673],\n",
       " [0.4007592797279358, -0.9161834120750427, -1.2449687719345093]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data import read_json \n",
    "reader = read_json(\"small_evl/output-2024-04-18_11-49-47_worker-0_0.json\")\n",
    "reader.take(1)[0]['obs'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:33:55,721\tINFO streaming_executor.py:112 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-04-18_11-52-57_167737_73576/logs\n",
      "2024-04-18 12:33:55,722\tINFO streaming_executor.py:113 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadJSON] -> LimitOperator[limit=1]\n",
      "\n",
      "                                                \n",
      "\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ImportanceSampling.estimate_on_single_step_samples() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimportance_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImportanceSampling\n\u001b[0;32m----> 2\u001b[0m estimates_per_episode \u001b[38;5;241m=\u001b[39m \u001b[43mImportanceSampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_on_single_step_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ImportanceSampling.estimate_on_single_step_samples() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "from ray.rllib.offline.estimators.importance_sampling import ImportanceSampling\n",
    "estimates_per_episode = ImportanceSampling.estimate_on_single_step_samples(batch=reader.take(1)[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-val batch=[[-0.00762615]]\n",
      "Q-val policy=[[-0.00702446]]\n"
     ]
    }
   ],
   "source": [
    "batch = synchronous_parallel_sample(worker_set=cql_algorithm.workers)\n",
    "batch = convert_ma_batch_to_sample_batch(batch)\n",
    "obs = torch.from_numpy(batch[\"obs\"])\n",
    "# Pass the observations through our model to get the\n",
    "# features, which then to pass through the Q-head.\n",
    "model_out, _ = cql_model({\"obs\": obs})\n",
    "# The estimated Q-values from the (historic) actions in the batch.\n",
    "q_values_old = cql_model.get_q_values(\n",
    "    model_out, torch.from_numpy(batch[\"actions\"])\n",
    ")[0]\n",
    "# The estimated Q-values for the new actions computed by our policy.\n",
    "actions_new = cql_policy.compute_actions_from_input_dict({\"obs\": obs})[0]\n",
    "q_values_new = cql_model.get_q_values(model_out, torch.from_numpy(actions_new))[0]\n",
    "print(f\"Q-val batch={q_values_old.detach().numpy()}\")\n",
    "print(f\"Q-val policy={q_values_new.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "file_path = 'small_evl/output-2024-04-18_11-49-47_worker-0_0.json'\n",
    "\n",
    "# Open the file and load the data\n",
    "data_list = []\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Load each line as a JSON object and append to list\n",
    "        json_obj = json.loads(line)\n",
    "        data_list.append(json_obj)\n",
    "\n",
    "# Normalize and concatenate all data into a single DataFrame\n",
    "df = pd.concat([pd.json_normalize(obj) for obj in data_list], ignore_index=True)\n",
    "\n",
    "df.to_csv('small_evl/output-2024-04-18_11-49-47_worker-0_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
